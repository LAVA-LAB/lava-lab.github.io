<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Constrained Multi-agent RL | AI-FM</title> <meta name="author" content="AI FM"/> <meta name="description" content="Reinforcement learning for multiple agents under cost constraints"/> <meta name="keywords" content="learning, verification, decision-making under uncertainty, ai"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img//logos/logoShield.svg"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ai-fm.github.io/projects/ConstrainedMultiagentRL/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">AI-FM</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/research/uncertainty_partial_information">Uncertainty and Partial Information</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/research/reinforcement_learning">Reinforcement Learning</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/research/dynamical_systems">Dynamical Systems</a> </div> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/resources/">Resources</a> </li> <li class="nav-item "> <a class="nav-link" href="/photos/">Photo Gallery</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">For Students</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/projects/#open">Open Projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/#ongoing">Ongoing Projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/#complete">Complete Projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/writing/">Writing Tips</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Constrained Multi-agent RL</h1> <p class="post-description">Reinforcement learning for multiple agents under cost constraints</p> </header> <article> <p><strong>Background:</strong> Many modern problems, such as the optimisation of cellular networks, can be formulated as a multi-agent system with cost constraints [1]. Using this formulation, we can use machine learning methods, such as <em>multi-agent reinforcement learning</em>, to find the optimal performance for the agents. Because of the rapid increase of complexity when many agents are involved, we often need to distribute the optimisation problem in a graphical structure that models (sparse) interactions between the agents. Existing techniques exist to optimise an unconstrained multi-agent problem given a graph [2]. However, it remains an open problem to efficiently formulate and optimise in a distributed manner while satisfying constraints.</p> <p><strong>Project:</strong> You will work on (multi-agent) reinforcement learning algorithms, such as Monte Carlo tree search, under cost constraints [3]. In particular, we are interested in determining if we can also decompose the optimisation objective using the graph, given that we must satisfy a maximum budget of expected costs. You can analyse the problem theoretically and/or extend the aforementioned (existing) algorithms. In the latter case, your supervisors can supply you with existing code from which you can start working.</p> <p>Affinity with or the motivation to learn about Markov decision processes and reinforcement learning is a big plus. Starting this project can easily lead you to a bachelor/master thesis and possibly to a scientific publication. Please feel free to reach out to maris.galesloot@ru.nl for any questions.</p> <p>[1] Albin Larsson Forsberg, Alexandros Nikou, Aneta Vulgarakis Feljan, Jana Tumova. Network Parameter Control in Cellular Networks through Graph-Based Multi-Agent Constrained Reinforcement Learning. IEEE, 2023.</p> <p>[2] Maris Galesloot, Thiago D. Simão, Sebastian Junges, Nils Jansen. Factored Online Planning in Many-Agent POMDPs. AAAI, 2024.</p> <p>[3] Jongmin Lee, Geon-hyeong Kim, Pascal Poupart, Kee-Eung Kim. Monte-Carlo Tree Search for Constrained POMDPs. NeurIPS, 2018.</p> <p><em>Supervisors:</em> <a href="https://marisgg.github.io/" target="_blank" rel="noopener noreferrer">Maris Galesloot MSc</a>, <a href="https://tdsimao.github.io/" target="_blank" rel="noopener noreferrer">Dr. Thiago D. Simão</a>, and <a href="https://nilsjansen.org/" target="_blank" rel="noopener noreferrer">Prof. Dr. Nils Jansen</a></p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 AI FM. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>