<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Active Measure MDPs | AI-FM</title> <meta name="author" content="AI FM"/> <meta name="description" content="Deciding the value of information in Markov decision processes"/> <meta name="keywords" content="learning, verification, decision-making under uncertainty, ai"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img//logos/logoShield.svg"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ai-fm.github.io/projects/ActiveMeasuring/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">AI-FM</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Research</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/research/uncertainty_partial_information">Uncertainty and Partial Information</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/research/reinforcement_learning">Reinforcement Learning</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/research/dynamical_systems">Dynamical Systems</a> </div> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/resources/">Resources</a> </li> <li class="nav-item "> <a class="nav-link" href="/photos/">Photo Gallery</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">For Students</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/projects/#open">Open Projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/#ongoing">Ongoing Projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/#complete">Complete Projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/writing/">Writing Tips</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Active Measure MDPs</h1> <p class="post-description">Deciding the value of information in Markov decision processes</p> </header> <article> <p>In reinforcement learning and planning problems, we often assume agents can observe their state for free, but this is often unrealistic. For example, inspections of machinery might require hiring (expensive) personnel, or constantly using a robot’s sensors might unnecessarily drain its battery.</p> <p>Active-measure MDPs (AM-MDPs) are a framework where we instead assume the agent mustdeliberately take a costly <em>measuring action</em> in order to determine its current state. In an RL setting, such costly measurements are useful both for <em>learning</em> an accurate representation of your environment, as well as for <em>computing</em> a better policy. Although methods for solving AM-MDPs exist, many focus on only one of these two benefits.</p> <p>In this project, we aim to combine or improve existing methods of solving AM-MPDs, such that they both cheaply learn a model as well as plan good policies for them.</p> <p><strong>During the project, you will:</strong></p> <ul> <li>Learn about reinforcement learning in general and AM-MDPs in particular;</li> <li>Extend our existing (Python) code with better exploration polcies.</li> </ul> <p><strong>References:</strong></p> <ol> <li>Colin Bellinger, Mark Crowley, Isaac Tamblyn (2020). Active Measure Reinforcement Learning for Observation Cost Minimization.</li> <li>Merlijn Krale, Thiago D. Simão and Nils Jansen (2023). Act-then-measure: reinforcement learning for partially observable environments with active measuring.</li> <li>Colin Bellinger, Mark Crowley and Isaac Tamblyn (2023). Learning in POMDPs is Sample-Efficient with Hindsight Observability</li> </ol> <p><em>Supervisors:</em> <a href="https://mkrale.com/" target="_blank" rel="noopener noreferrer">Merlijn Krale Msc</a>, <a href="https://tdsimao.github.io/" target="_blank" rel="noopener noreferrer">Dr. Thiago D. Simão</a> and <a href="https://nilsjansen.org/" target="_blank" rel="noopener noreferrer">Prof. Dr. Nils Jansen</a></p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 AI FM. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>