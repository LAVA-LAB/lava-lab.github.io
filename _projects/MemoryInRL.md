---
layout: page
title: Memory in RL
description: Memory architectures in reinforcement learning
img: assets/img/projects/FishSwarm.jpg
importance: 1
category: open
---

**Background:** Reinforcement learning (RL) is the prevalent framework to control agents in high-dimensional environments. In realistic domains, such environments are partially observable, for instance, because the agent needs to act based on vision or sensory inputs, or require reasoning over past actions. Agents requires memory to act optimally in partially observable environments. In deep RL, various architectures have been proposed to enable agents with memory. However, there is still much progress to be made in how to balance short and long term memory of the agent, how to accurately represent the history of observations of the agent's environment, and how to efficiently learn with memory.

**Project:** You will test memory architectures for (deep) RL algorithms, such as the newly introduced sLSTM, and compare it to existing architectures, like the LSTM and GRU and dedicated architectures for deep RL in partially observable environments. You can also look into developing a (specialised) architecture to accommodate memory. Your supervisors can supply you with existing code from which you can start working.

Affinity with or the motivation to learn about Markov decision processes and reinforcement learning is a big plus. Starting this project can easily lead you to a bachelor/master thesis and possibly to a scientific publication. Please feel free to reach out to maris.galesloot@ru.nl for any questions.

*Supervisors:* [Maris Galesloot MSc](https://marisgg.github.io/), and [Prof. Dr. Nils Jansen](https://nilsjansen.org/)
